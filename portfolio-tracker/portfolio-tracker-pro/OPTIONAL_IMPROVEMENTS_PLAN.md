# ğŸ“‹ Plan Opcjonalnych UlepszeÅ„ - Portfolio Tracker Pro

## ğŸ¯ **CEL:**
ZwiÄ™kszenie inteligencji aplikacji i poprawa jakoÅ›ci danych w czasie rzeczywistym.

---

## ğŸ” **ULEPSZENIE 1: Smart Insights Service - Enhancements**

### **Obecny Stan:**
- âœ… Podstawowy `SmartInsightsService` istnieje
- âœ… Enhanced Recommendations juÅ¼ zaimplementowane (rebalancing calculator, tax-loss harvesting)
- âš ï¸ Brak zaawansowanych alertÃ³w o ryzyku
- âš ï¸ Brak automatycznych sugestii rebalansowania w czasie rzeczywistym

### **Co ZaimplementowaÄ‡:**

#### **1.1. Real-time Risk Alerts** (2-3h)
**Backend:**
- RozszerzyÄ‡ `SmartInsightsService` o metodÄ™ `detect_risk_alerts()`
- Wykrywanie:
  - Koncentracja ryzyka (>40% w jednym aktywie)
  - Nadmierna korelacja (>0.8 miÄ™dzy aktywami)
  - Wysoka volatility (>50% rocznie)
  - DuÅ¼y drawdown (>20% od szczytu)
- Endpoint: `GET /api/insights/risk-alerts`
- Cache: 5 minut (ryzyko moÅ¼e siÄ™ szybko zmieniaÄ‡)

**Frontend:**
- Komponent `RiskAlertsPanel` w Dashboard
- Wizualne wskaÅºniki ryzyka (kolorowe chipsy)
- Auto-refresh co 30 sekund
- Linki do szczegÃ³Å‚Ã³w (drill-down)

#### **1.2. Automatic Rebalancing Suggestions** (3-4h)
**Backend:**
- Metoda `generate_rebalancing_suggestions()` w `SmartInsightsService`
- Analiza:
  - Obecna alokacja vs optymalna (z Portfolio Optimizer)
  - Drift detection (odchylenie >5%)
  - Koszt rebalansowania (spread, fees)
  - Tax implications
- Endpoint: `GET /api/insights/rebalancing-suggestions`
- Parametry:
  - `threshold`: prÃ³g driftu (default: 5%)
  - `include_tax`: uwzglÄ™dniaÄ‡ podatki (default: true)
  - `max_suggestions`: max liczba sugestii (default: 5)

**Frontend:**
- Sekcja "Rebalancing Suggestions" w Dashboard
- Karty z sugestiami:
  - Symbol, obecna alokacja, docelowa alokacja
  - Kwota do kupna/sprzedaÅ¼y
  - Oszacowany koszt (fees, spread)
  - Potencjalne korzyÅ›ci (risk reduction, expected return)
- Przycisk "Apply Suggestions" (opcjonalnie - przyszÅ‚oÅ›Ä‡)

#### **1.3. Portfolio Health Score** (2-3h)
**Backend:**
- Metoda `calculate_portfolio_health()` w `SmartInsightsService`
- Czynniki:
  - Dywersyfikacja (liczba aktywÃ³w, sektory, regiony)
  - Koncentracja ryzyka
  - PÅ‚ynnoÅ›Ä‡ portfela
  - Koszt efektywnoÅ›ci (fees, spread)
- Score: 0-100 (0 = bardzo zÅ‚y, 100 = doskonaÅ‚y)
- Endpoint: `GET /api/insights/health-score`

**Frontend:**
- Health Score widget w Dashboard
- Wizualizacja: progress bar + kolor (red/yellow/green)
- Breakdown: szczegÃ³Å‚y kaÅ¼dego czynnika
- Trend: zmiana w czasie (jeÅ›li dostÄ™pne dane historyczne)

#### **1.4. Market Sentiment Integration** (4-5h) - OPCJONALNE
**Backend:**
- Integracja z news API (jeÅ›li dostÄ™pne)
- Analiza sentymentu dla aktywÃ³w w portfolio
- Endpoint: `GET /api/insights/sentiment/{symbol}`
- Cache: 1 godzina

**Frontend:**
- Sentiment indicators w AssetTabs
- Kolorowe wskaÅºniki (bullish/bearish/neutral)

### **Szacowany Czas: 11-15 godzin**

---

## âš¡ **ULEPSZENIE 2: Real-time Data Accuracy - Improvements**

### **Obecny Stan:**
- âœ… `MarketDataService` dziaÅ‚a
- âœ… Podstawowe cache'owanie
- âœ… Fallbacki do rÃ³Å¼nych ÅºrÃ³deÅ‚
- âš ï¸ Brak inteligentnego zarzÄ…dzania rate limitami
- âš ï¸ Brak priorytetyzacji requestÃ³w
- âš ï¸ Brak automatycznego retry z backoff

### **Co ZaimplementowaÄ‡:**

#### **2.1. Intelligent Rate Limit Management** (3-4h)
**Backend:**
- Klasa `RateLimitManager` w `market_data_service.py`
- Funkcje:
  - Tracking requestÃ³w per API provider
  - Automatyczne throttling przy zbliÅ¼aniu siÄ™ do limitu
  - Priority queue dla requestÃ³w (krytyczne > normalne > background)
  - Distributed rate limiting (jeÅ›li wiele instancji backendu)
- Implementacja:
  ```python
  class RateLimitManager:
      def __init__(self):
          self.providers = {
              'binance': {'limit': 1200, 'window': 60, 'current': 0},
              'yfinance': {'limit': 2000, 'window': 60, 'current': 0},
              # ...
          }
      
      def can_make_request(self, provider: str, priority: str = 'normal') -> bool
      def record_request(self, provider: str)
      def get_wait_time(self, provider: str) -> float
  ```

**Integracja:**
- UÅ¼ywaÄ‡ w `get_price()`, `get_symbol_history()`, `get_watchlist_prices()`
- Automatyczne opÃ³Åºnianie requestÃ³w przy rate limit
- Logowanie warningÃ³w przy zbliÅ¼aniu siÄ™ do limitu

#### **2.2. Request Prioritization System** (2-3h)
**Backend:**
- Priority levels:
  - `critical`: Dashboard summary, active alerts (0 delay)
  - `high`: User portfolio assets, watchlist prices (100ms delay)
  - `normal`: Historical data, analytics (500ms delay)
  - `low`: Background prefetch, non-critical data (2000ms delay)
- Implementacja w `MarketDataService`:
  ```python
  async def get_price(self, symbol: str, priority: str = 'normal') -> Dict:
      if not rate_limit_manager.can_make_request('provider', priority):
          wait_time = rate_limit_manager.get_wait_time('provider')
          await asyncio.sleep(wait_time)
      # ... make request
  ```

**Frontend:**
- Parametr `priority` w `portfolioService` methods:
  - `getSummary()` â†’ `critical`
  - `getAssets()` â†’ `high`
  - `getAdvancedAnalytics()` â†’ `normal`
  - `prefetchContextualData()` â†’ `low`

#### **2.3. Enhanced Fallback Strategy** (2-3h)
**Backend:**
- Hierarchia ÅºrÃ³deÅ‚ danych:
  1. Primary source (np. Binance API dla crypto)
  2. Secondary source (np. CoinGecko dla crypto)
  3. Tertiary source (np. yfinance jako fallback)
  4. Cached data (jeÅ›li wszystkie ÅºrÃ³dÅ‚a fail)
- Automatyczne przeÅ‚Ä…czanie przy bÅ‚Ä™dach
- Health checks dla kaÅ¼dego ÅºrÃ³dÅ‚a
- Circuit breaker pattern (temporary disable przy wielokrotnych bÅ‚Ä™dach)

**Implementacja:**
```python
class DataSourceManager:
    def __init__(self):
        self.sources = {
            'crypto': [
                {'name': 'binance', 'priority': 1, 'healthy': True},
                {'name': 'coingecko', 'priority': 2, 'healthy': True},
                {'name': 'yfinance', 'priority': 3, 'healthy': True}
            ]
        }
    
    async def get_data(self, symbol: str, data_type: str) -> Dict:
        for source in sorted_sources:
            try:
                return await self._fetch_from_source(source, symbol)
            except Exception as e:
                self._mark_unhealthy(source)
                continue
        # All sources failed, return cached data
        return self._get_cached_data(symbol)
```

#### **2.4. Smart Caching with TTL per Data Type** (2-3h)
**Backend:**
- RÃ³Å¼ne TTL dla rÃ³Å¼nych typÃ³w danych:
  - Real-time prices: 5-10 sekund
  - Historical data: 1 godzina
  - Analytics: 15 minut
  - Static data (symbol info): 24 godziny
- Cache invalidation strategy:
  - Time-based (TTL)
  - Event-based (gdy dane siÄ™ zmieniajÄ…)
  - Manual (przez endpoint)
- Cache warming dla krytycznych danych

**Implementacja w `MarketDataService`:**
```python
CACHE_TTL = {
    'price': 10,  # seconds
    'history': 3600,  # 1 hour
    'analytics': 900,  # 15 minutes
    'symbol_info': 86400  # 24 hours
}

def get_cached_or_fetch(self, key: str, fetch_fn, ttl: int):
    cached = self.cache.get(key)
    if cached and not self._is_expired(cached, ttl):
        return cached['data']
    data = fetch_fn()
    self.cache.set(key, {'data': data, 'timestamp': time.time()}, ttl)
    return data
```

#### **2.5. Automatic Retry with Exponential Backoff** (1-2h)
**Backend:**
- Retry logic z exponential backoff dla:
  - Network errors (timeout, connection error)
  - Rate limit errors (429)
  - Temporary server errors (503, 502)
- Nie retry dla:
  - Client errors (400, 401, 404)
  - Permanent errors (500 bez retry-after header)
- Configurable max retries per request type

**Implementacja:**
```python
async def fetch_with_retry(self, url: str, max_retries: int = 3, 
                          base_delay: float = 1.0) -> Dict:
    for attempt in range(max_retries):
        try:
            return await self._fetch(url)
        except (TimeoutError, ConnectionError, HTTPException) as e:
            if attempt == max_retries - 1:
                raise
            delay = base_delay * (2 ** attempt)
            await asyncio.sleep(delay)
    raise Exception("Max retries exceeded")
```

#### **2.6. Data Quality Monitoring** (2-3h)
**Backend:**
- Monitoring jakoÅ›ci danych:
  - Staleness detection (czy dane sÄ… aktualne)
  - Anomaly detection (nieoczekiwane zmiany cen)
  - Data completeness (czy wszystkie wymagane pola sÄ… wypeÅ‚nione)
- Endpoint: `GET /api/market-data/quality-report`
- Logging do pliku/metrics dla analizy

**Frontend:**
- WskaÅºnik jakoÅ›ci danych w Dashboard
- OstrzeÅ¼enia gdy dane mogÄ… byÄ‡ nieaktualne
- Opcja rÄ™cznego odÅ›wieÅ¼enia

### **Szacowany Czas: 12-18 godzin**

---

## ğŸ“Š **PODSUMOWANIE**

| Ulepszenie | Czas | Priorytet | WpÅ‚yw |
|------------|------|-----------|-------|
| **1.1. Real-time Risk Alerts** | 2-3h | Wysoki | â­â­â­ |
| **1.2. Automatic Rebalancing Suggestions** | 3-4h | Wysoki | â­â­â­ |
| **1.3. Portfolio Health Score** | 2-3h | Åšredni | â­â­ |
| **1.4. Market Sentiment Integration** | 4-5h | Niski | â­ |
| **2.1. Rate Limit Management** | 3-4h | Wysoki | â­â­â­ |
| **2.2. Request Prioritization** | 2-3h | Wysoki | â­â­â­ |
| **2.3. Enhanced Fallback Strategy** | 2-3h | Åšredni | â­â­ |
| **2.4. Smart Caching** | 2-3h | Åšredni | â­â­ |
| **2.5. Retry with Backoff** | 1-2h | Åšredni | â­â­ |
| **2.6. Data Quality Monitoring** | 2-3h | Niski | â­ |

**Total: 23-33 godzin pracy**

---

## ğŸ¯ **REKOMENDOWANY PLAN DZIAÅANIA**

### **Faza 1: Critical Improvements (8-10h)**
1. **1.1. Real-time Risk Alerts** (2-3h)
2. **1.2. Automatic Rebalancing Suggestions** (3-4h)
3. **2.1. Rate Limit Management** (3-4h)

### **Faza 2: Important Improvements (6-9h)**
4. **2.2. Request Prioritization** (2-3h)
5. **2.3. Enhanced Fallback Strategy** (2-3h)
6. **1.3. Portfolio Health Score** (2-3h)

### **Faza 3: Nice to Have (9-14h)**
7. **2.4. Smart Caching** (2-3h)
8. **2.5. Retry with Backoff** (1-2h)
9. **2.6. Data Quality Monitoring** (2-3h)
10. **1.4. Market Sentiment Integration** (4-5h) - OPCJONALNE

---

## ğŸš€ **NASTÄ˜PNE KROKI**

1. **ZatwierdÅº plan** - czy te ulepszenia sÄ… w odpowiedniej kolejnoÅ›ci?
2. **Wybierz fazÄ™** - od ktÃ³rej fazy zaczÄ…Ä‡?
3. **Zacznij implementacjÄ™** - Faza 1 daje najwiÄ™kszy wpÅ‚yw

---

## ğŸ“ **NOTATKI**

- Wszystkie ulepszenia sÄ… backward compatible
- MoÅ¼na implementowaÄ‡ stopniowo
- KaÅ¼de ulepszenie moÅ¼na testowaÄ‡ niezaleÅ¼nie
- Priorytety moÅ¼na zmieniaÄ‡ w zaleÅ¼noÅ›ci od potrzeb

